{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was used to load sufficient data involving the streets both perpendicular and parallel to Halsted St. Then, two major intersections from all the covered intersections were chosen to train the single agent PPO model. This code segment was also used in the initial stage of our project to perform data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import plotly.express as px\n",
    "import sqlite3\n",
    "import logging\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "from datetime import datetime, time, timedelta\n",
    "\n",
    "url = \"https://data.cityofchicago.org/resource/sxs8-h27x.json\"\n",
    "\n",
    "#Initialize query parameters\n",
    "params = {\n",
    "        \"$limit\": 500000,\n",
    "        \"$offset\": 0,\n",
    "        \"$where\": \"caseless_one_of(street, 'Halsted') OR caseless_one_of(from_street, 'Halsted')\" +\n",
    "        \"OR caseless_one_of(to_street, 'Halsted')\",\n",
    "        \"$order\": \"time DESC\"\n",
    "    }\n",
    "\n",
    " \n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(\"Failed to retrieve data.\")\n",
    "    exit()\n",
    "print(\"Data loaded\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(response.json())\n",
    "\n",
    "# Check for missing values in latitude/longitude columns\n",
    "df = df.dropna(subset=[\"start_latitude\", \"start_longitude\"])\n",
    "\n",
    "dfHalsted = df[df['street'] == 'Halsted']\n",
    "dfFromHalsted = df[df['from_street'] == 'Halsted']\n",
    "dfToHalsted = df[df['to_street'] == 'Halsted']\n",
    "\n",
    "insert_statement = \"INSERT INTO chicago_traffic_dataset_table (time, segment_id, speed, message_count, street, from_street, to_street, hour, day_of_week, start_latitude, start_longitude, end_latitude, end_longitude, time_indices) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    " \n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS chicago_traffic_dataset_table (\n",
    "    time TEXT,\n",
    "    segment_id TEXT,\n",
    "    speed REAL,\n",
    "    message_count TEXT,\n",
    "    street TEXT,\n",
    "    from_street TEXT,\n",
    "    to_street TEXT,\n",
    "    hour INTEGER,\n",
    "    day_of_week INTEGER,\n",
    "    start_latitude REAL,\n",
    "    start_longitude REAL,\n",
    "    end_latitude REAL,\n",
    "    end_longitude REAL,\n",
    "    time_indices INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowsegment_df = pd.read_csv('ImportantFlowSegments.csv')\n",
    "\n",
    "def store_to_sqlite(df, db_name, table_name): #store extracted Chicago traffic data to the database\n",
    "    if df.empty:\n",
    "        logging.warning(\"DataFrame is empty; no data to store.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with sqlite3.connect(db_name) as conn:\n",
    "            print(\"Storing in database...\")\n",
    "            print(df.shape[0])\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(create_table_query)\n",
    "            conn.commit()\n",
    "            \n",
    "            for idx, row in df.iterrows():\n",
    "                cursor.execute(insert_statement, (row['time'], row['segment_id'], row['speed'], row['message_count'], row['street'], row['from_street'], row['to_street'], row['hour'], row['day_of_week'], row['start_latitude'], row['start_longitude'], row['end_latitude'], row['end_longitude'], row['time_indices']))\n",
    "            conn.commit()\n",
    "\n",
    "            logging.info(f\"Data successfully stored in {db_name} under {table_name}.\")\n",
    "            print(cursor.execute(\"SELECT COUNT(*) FROM chicago_traffic_dataset_table\").fetchone()[0])\n",
    "    except sqlite3.Error as e:\n",
    "        logging.error(f\"Database error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"Clean the DataFrame by handling missing values.\"\"\"\n",
    "    # Check for missing values\n",
    "    logging.info(\"Checking for missing values...\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    logging.info(f\"Missing values: {missing_values[missing_values > 0]}\")\n",
    "\n",
    "    # Forward fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Convert any dictionary-type columns to strings\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].apply(lambda x: str(x) if isinstance(x, dict) else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "def adjust_negative_values(df):\n",
    "    new_speeds = []\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['speed'] == '-1':\n",
    "            new_speeds.append('0')\n",
    "        else:\n",
    "            new_speeds.append(row['speed'])\n",
    "\n",
    "    df['speed'] = new_speeds\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Folium map centered around Chicago\n",
    "chicago_map = folium.Map(location=[41.8781, -87.6298], zoom_start=12)\n",
    "\n",
    "data_rows = []\n",
    "for id, row in dfHalsted.iterrows():\n",
    "  if int(row['segment_id']) in flowsegment_df['segment_id'].to_list():\n",
    "      data_rows.append(row)\n",
    "      folium.Marker(location=[row['start_latitude'], row['start_longitude']],\n",
    "                  popup = \"From \" + row['from_street'] + \" To \" + row['to_street'] + \" Start latitude: \" \n",
    "                  + row['start_latitude'] + \" Start longitude: \" + row['start_longitude'],\n",
    "                  icon = folium.Icon(color=\"green\", icon=\"play\")).add_to(chicago_map)\n",
    "\n",
    "\n",
    "      folium.Marker(location=[row['end_latitude'], row['end_longitude']],\n",
    "                  popup=\"From \" + row['from_street'] + \" To \" + row['to_street'] + \" End latitude: \" \n",
    "                  + row['end_latitude'] + \" End longitude: \" + row['end_longitude'],\n",
    "                  icon = folium.Icon(color='red', icon='pause')).add_to(chicago_map)\n",
    "\n",
    "\n",
    "for id, row in dfFromHalsted.iterrows():\n",
    "  if int(row['segment_id']) in flowsegment_df['segment_id'].to_list():\n",
    "      data_rows.append(row)\n",
    "      folium.Marker(location = [row['start_latitude'], row['start_longitude']],\n",
    "                   popup = \"From Halsted to \" + row['to_street'] + \" Start latitude: \" + row['start_latitude']\n",
    "                    + \" Start longitude: \" + row['start_longitude'],\n",
    "                   icon = folium.Icon(color='green', icon='play')).add_to(chicago_map)\n",
    "      folium.Marker(location=[row['end_latitude'], row['end_longitude']],\n",
    "                  popup=\"From Halsted to \" + row['to_street'] + \" End latitude: \" + row['end_latitude'] \n",
    "                  + \" End longitude: \" + row['end_longitude'],\n",
    "                  icon = folium.Icon(color='red', icon='pause')).add_to(chicago_map)\n",
    "    \n",
    "for id, row in dfToHalsted.iterrows():\n",
    "  if int(row['segment_id']) in flowsegment_df['segment_id'].to_list():\n",
    "      data_rows.append(row)\n",
    "      folium.Marker(location = [row['start_latitude'], row['start_longitude']],\n",
    "                   popup = \"From \" + row[\"from_street\"] + \" to Halsted\" + \" Start latitude: \" + row['start_latitude'] \n",
    "                   + \" Start longitude: \" + row['start_longitude'],\n",
    "                   icon = folium.Icon(color='green', icon='play')).add_to(chicago_map)\n",
    "      folium.Marker(location=[row['end_latitude'], row['end_longitude']],\n",
    "                  popup=\"From \" + row[\"from_street\"] + \" to Halsted\" + \" End latitude: \" + row['end_latitude'] \n",
    "                  + \" End longitude: \" + row['end_longitude'],\n",
    "                  icon = folium.Icon(color='red', icon='pause')).add_to(chicago_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t_om\\AppData\\Local\\Temp\\ipykernel_15520\\1497556278.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1239, 1203, 1204, 1240, 409, 454, 455, 448, 1238, 1202, 273, 259, 274, 258, 1237, 1201]\n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrame, clean data, and store in the database\n",
    "adjacent_df = clean_data(pd.DataFrame(data_rows))\n",
    "\n",
    "# Convert any dictionary-type columns to strings\n",
    "for col in adjacent_df.columns:\n",
    "        if adjacent_df[col].dtype == 'object':\n",
    "            adjacent_df[col] = adjacent_df[col].apply(lambda x: str(x) if isinstance(x, dict) else x)\n",
    "\n",
    "\n",
    "            #Store cleaned data to sql database\n",
    "\n",
    "# Save the map with markers\n",
    "chicago_map.save('chicago_folium_map.html')\n",
    "\n",
    "filtered_rows = []\n",
    "times = []\n",
    "print(flowsegment_df['segment_id'].to_list())\n",
    "\n",
    "for idx, row in adjacent_df.iterrows():\n",
    "    if int(row['segment_id']) in flowsegment_df['segment_id'].to_list():\n",
    "       time_object = datetime.strptime(row['time'], \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "       hour_minute = time(time_object.hour, time_object.minute)\n",
    "       times.append(hour_minute)\n",
    "       filtered_rows.append(row)\n",
    "\n",
    "start_time = min(times) #set minimum time\n",
    "new_df = pd.DataFrame(filtered_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing in database...\n",
      "62496\n",
      "62496\n"
     ]
    }
   ],
   "source": [
    "adjusted_df = adjust_negative_values(new_df)\n",
    "index = 0\n",
    "time_indices = []\n",
    "for idx, row in adjusted_df.iterrows():\n",
    "    count = 1\n",
    "    start = timedelta(hours=start_time.hour, minutes=start_time.minute)\n",
    "    while (timedelta(hours=times[index].hour, minutes=times[index].minute) - start) >= timedelta(minutes=9):\n",
    "        start+=timedelta(minutes = 10)\n",
    "        count+=1\n",
    "    time_indices.append(count)\n",
    "    index+=1\n",
    "\n",
    "adjusted_df['time_indices'] = time_indices\n",
    "\n",
    "store_to_sqlite(adjusted_df,'traffic_interval_data.db','chicago_traffic_dataset_table')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
